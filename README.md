# LLM Health Assistant â€“ Prompt Evaluation Demo

This project demonstrates a simplified AI health assistant workflow inspired by real-world healthcare AI systems.

## Goals
- Show how prompts can be structured for safety
- Demonstrate basic AI guardrails
- Evaluate whether model responses meet safety expectations

## Features
- System prompt defining AI behavior boundaries
- Example user health-related queries
- Response evaluation for:
  - Professional referral suggestions
  - Safety disclaimers
  - Appropriate response length

## Why This Matters
In healthcare AI, it's critical that models:
- Avoid giving diagnoses
- Encourage professional care when needed
- Provide safe, structured guidance

This project simulates how AI outputs can be tested and validated before deployment.
